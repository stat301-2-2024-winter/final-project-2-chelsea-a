---
title: "Progress Memo 2"
subtitle: |
  | Final Project 
  | Data Science 2 with R (STAT 301-2)
author: "Chelsea Angwenyi"
date: today

format:
  html:
    toc: true
    embed-resources: true
    
execute:
  echo: false
  warning: false

from: markdown+emoji 
reference-location: margin
citation-location: margin
---

::: {.callout-tip icon=false}

## Github Repo Link
[my github repo url](https://github.com/stat301-2-2024-winter/final-project-2-chelsea-a)

:::

## Data Overview

My data came from the UC Irvine Machine Learning Repository and is called [Predict Students' Dropout and Academic Success](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success). This data is from one higher education institution (acquired from several disjoint databases) related to students enrolled in different undergraduate degrees. The dataset includes information known at the time of student enrollment and the student's academic performance at the end of the first and second semesters. The dataset is formulated as a three-category classification task with the target variable being either dropout, enrolled, or graduate. Therefore, I will be predicting whether a student drops out of college with this particular data.

I decided to split the data 80/20 and make 10 folds out of the training data. So far I have fit a logistic model and a baseline logistic model on training data.

##  Models
For my baseline model, I used a logistic regression model with categorical variables dummy encoded, numeric predictors normalized, and zero variance predictors removed.

I then made a second model that used a different recipe that included interactions. The interactions were between gender and semester grade as well as between marital status and semester grade. After I fit the model using training data.


```{r}
#| label: log
#| echo: false
library(tidyverse)
library(here)

read_csv(here("figures/accuracy.csv")) |> knitr::kable()
```
While the accuracy of the logistic regression model is slightly better than the accuracy of the baseline model, both models performed poorly at less than 40% accuracy.

## Plan
I plan to fit my models on my training folds next time for increased accuracy. I will also make a random forest model with tuned hyperparameters as well. I plan to use other metrics besides accuracy such as roc_auc to assess metrics as well. 

# Potential issues or concerns
I find it a bit concerning that the accuracy is as low as it is.

At one point I threw an error stating that my target variable is not binary as it has three levels: dropout, enrolled, and graduate. I am wondering if this will be an issue further on. 

I was unable to use predict() on my tuned random forest model due to it being a classification model and am not sure how to fix this.

I was also unable to fit my logistic regression model on the folds and instead fit the models on training data. 

## References
M.V.Martins, D. Tolledo, J. Machado, L. M.T. Baptista, V.Realinho. (2021) "Early prediction of student’s performance in higher education: a case study" Trends and Applications in Information Systems and Technologies, vol.1, in Advances in Intelligent Systems and Computing series. Springer. DOI: 10.1007/978-3-030-72657-7_16

This dataset is supported by the program SATDAP - Capacitação da Administração Pública under grant POCI-05-5762-FSE-000191, Portugal.
